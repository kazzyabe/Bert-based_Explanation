# -*- coding: utf-8 -*-
"""bert_similarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZsaciMwmDMwpmO6F070-viwOVHzcQEbw

# Installing sentence-transformers and Loading raw data
"""

# !pip install -U sentence-transformers

import pandas as pd

url = 'https://raw.githubusercontent.com/kazzyabe/Bert-based_Explanation/master/bert-based_explanation/bert_data_proccessed.csv'

data = pd.read_csv(url)
data['label']=1-data['decision']

"""# Bert Embeddings and similarity"""

from sentence_transformers import SentenceTransformer,CrossEncoder,losses,util,InputExample,SentencesDataset
from sklearn import metrics
from sklearn.model_selection import StratifiedKFold,KFold
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torch import nn

def cos_sim(d,model):
	emb1 = model.encode(d['query_p'])
	emb2 = model.encode(d['citation_p'])
	cos_sim =util.pytorch_cos_sim(emb1, emb2)
	return cos_sim.item()

def sts_sim(d,model):
	scores = model.predict(d)
	return scores

def kfoldtest(data):
	data = data.sample(frac=1,random_state=1).reset_index(drop=True)
	skf = KFold(n_splits=100)
	splits=[(x,y) for x,y in skf.split(data)]
	f1list=[]
	acclist=[]
	import torch
	print(torch.cuda.is_available())
	for b in [20]:
		for l in [2e-5]:
			for e in [4]:
				yh=np.array([])
				y=np.array([])
				i=0
				for train_index, test_index in splits:
					i+=1
					print(f"Fold {i}")
					#resetting the model for every fold
					model=CrossEncoder('cross-encoder/stsb-roberta-base',num_labels=1)
					#train split
					train=data.loc[train_index]
					#test split
					test=data.loc[test_index]
					#data loaders
					train_=SentencesDataset([InputExample(texts=[d['query_p'],d['citation_p']],label=int(d['label'])) for i,d in train.iterrows()],model)
					test_=SentencesDataset([InputExample(texts=[d['query_p'],d['citation_p']],label=int(d['label'])) for i,d in test.iterrows()],model)
					train_=DataLoader(train_,batch_size=b)
					test_=DataLoader(test_)
					#training
					model.fit(train_,epochs=e,optimizer_params={'lr':l})
					#predictions using cos_similarity
					y=np.append(y,test['label'])
					dlist=list(test.apply(lambda d:(d['query_p'],d['citation_p']), axis=1))
					yh=np.append(yh,sts_sim(dlist,model))
				#f1
				f1scores,thresholds=f1_macro(y,yh)
				print(np.nan in f1scores)
				f1=max(f1scores)
				f1list.append(f1)
				print(f1)
				#accuracy
				mthres=thresholds[np.nanargmax(f1scores)]
				yh1=np.zeros(len(yh))
				yh1[yh>=mthres]=1
				f12=metrics.f1_score(y,yh1,average='macro')
				if f12!=f1:
					import pdb
					pdb.set_trace()
				acc=metrics.accuracy_score(y, yh1)
				print(acc)
				acclist.append(acc)
				print(b,l,e)
				print("BERT Fine-Tuned: Average F1 across folds:",np.mean(f1list))
				print("BERT Fine-Tuned: Average Acc across folds:",np.mean(acclist))

def stratifiedkfoldtest(data):
	data = data.sample(frac=1,random_state=1).reset_index(drop=True)
	skf = StratifiedKFold(n_splits=10)
	splits=[(x,y) for x,y in skf.split(data, data['label'])]
	f1list=[]
	acclist=[]
	import torch
	torch.cuda.empty_cache()
	t = torch.cuda.get_device_properties(0).total_memory
	r = torch.cuda.memory_reserved(0) 
	a = torch.cuda.memory_allocated(0)
	f = r-a  # free inside reserved
	print(f"Total:{t/1e+9}, Reserved:{r}, Allocated:{a}, Free:{f}")
	for b in [24]:
	  for l in [2e-5]:
	    for e in [4]:
	      for train_index, test_index in splits:
	        #resetting the model for every fold
	        model=CrossEncoder('cross-encoder/stsb-roberta-base',num_labels=1)
	        #train split
	        train=data.loc[train_index]
	        #test split
	        test=data.loc[test_index]
	        #data loaders
	        train_=SentencesDataset([InputExample(texts=[d['query_p'],d['citation_p']],label=int(d['label'])) for i,d in train.iterrows()],model)
	        test_=SentencesDataset([InputExample(texts=[d['query_p'],d['citation_p']],label=int(d['label'])) for i,d in test.iterrows()],model)
	        train_=DataLoader(train_,batch_size=b)
	        test_=DataLoader(test_)
	        #loss function
	        #training
	        model.fit(train_,epochs=e,optimizer_params={'lr':l})
	        #predictions using encoder similarity
	        y=test['label']
	        dlist=list(test.apply(lambda d:(d['query_p'],d['citation_p']), axis=1))
	        yh=sts_sim(dlist,model)
	        #f1
	        f1scores,thresholds=f1_macro(y,yh)
	        print(np.nan in f1scores)
	        f1=max(f1scores)
	        f1list.append(f1)
	        print(f1)
	        #accuracy
	        mthres=thresholds[np.nanargmax(f1scores)]
	        yh1=np.zeros(len(yh))
	        yh1[yh>=mthres]=1
	        f12=metrics.f1_score(y,yh1,average='macro')
	        if f12!=f1:
	        	import pdb
	        	pdb.set_trace()
	        acc=metrics.accuracy_score(y, yh1)
	        print(acc)
	        acclist.append(acc)
	      print(b,l,e)
	      print("Average Macro F1 across folds:",np.mean(f1list))
	      print("Average Acc across folds:",np.mean(acclist))

def f1_macro(y,yh):
	thresholds=np.sort(np.unique(yh))
	f1s=[]
	for i in thresholds:
		yt=np.zeros(len(yh))
		yt[yh>=i]=1
		f1s.append(metrics.f1_score(y,yt,average='macro'))
	return np.array(f1s),thresholds

def bert(data):
	model=CrossEncoder('cross-encoder/stsb-roberta-base',num_labels=1)
	dlist=list(data.apply(lambda d:(d['query_p'],d['citation_p']), axis=1))
	y=data['label']
	yh=sts_sim(dlist,model)
	#f1
	f1scores,thresholds=f1_macro(y,yh)
	print(np.nan in f1scores)
	f1=max(f1scores)
	#accuracy
	mthres=thresholds[np.nanargmax(f1scores)]
	yh1=np.zeros(len(yh))
	yh1[yh>=mthres]=1
	f12=metrics.f1_score(y,yh1,average='macro')
	if f12!=f1:
		import pdb
		pdb.set_trace()
	acc=metrics.accuracy_score(y, yh1)
	print("BERT: Macro F1:",f1)
	print("BERT: Accuracy:",acc)
from sklearn.metrics.pairwise import cosine_similarity,cosine_distances

def bertcbr(data,n_neighbors):
	model=SentenceTransformer('stsb-roberta-base')
	q_embed=model.encode(data['query_p'])
	c_embed=model.encode(data['citation_p'])
	cases=np.concatenate((q_embed,c_embed),axis=1)
	# cases=np.subtract(q_embed,c_embed)
	X=np.arccos(np.clip(cosine_similarity(cases,cases),-1,1))/np.pi
	np.fill_diagonal(X,np.nan)
	Xn=np.argpartition(X,n_neighbors)[:,:n_neighbors]
	y=np.array(list(data['label']))
	yh=np.zeros(len(y))
	#Splits
	for i in range(Xn.shape[0]):
		ys=[]
		y_weights=[]
		for j in range(Xn.shape[1]):
			ys.append(y[Xn[i,j]])
			y_weights.append(1-X[i,Xn[i,j]])
		yh[i]=np.average(ys,weights=y_weights)
	#f1
	f1scores,thresholds=f1_macro(y,yh)
	print(np.nan in f1scores)
	f1=max(f1scores)
	#accuracy
	mthres=thresholds[np.nanargmax(f1scores)]
	yh1=np.zeros(len(yh))
	yh1[yh>=mthres]=1
	f12=metrics.f1_score(y,yh1,average='macro')
	if f12!=f1:
		import pdb
		pdb.set_trace()
	acc=metrics.accuracy_score(y, yh1)
	print("BERT CBR: Macro F1:",f1)
	print("BERT CBR: Accuracy:",acc)

def cbr_neur(data):
	y=np.array(list(data['label']))
	neur=np.load("neur.npy")
	from scipy.special import expit 
	# neur=expit(neur)
	yh=(neur-min(neur))/(max(neur)-min(neur))
	yh=yh.T[0]
	f1scores,thresholds=f1_macro(y,yh)
	yh=np.zeros(len(y))
	f1=max(f1scores)
	print(f1)
	#accuracy
	mthres=thresholds[np.nanargmax(f1scores)]
	yh1=np.zeros(len(yh))
	yh1[yh>=mthres]=1
	acc=metrics.accuracy_score(y, yh1)
	print(acc)


"""Final Results"""
# stratifiedkfoldtest(data)
kfoldtest(data)
bert(data)
bertcbr(data,3)
# cbr_neur(data)
