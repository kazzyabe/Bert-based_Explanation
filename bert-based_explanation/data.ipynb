{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../cases/cases used in study.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>problem.1</th>\n",
       "      <th>problem.2</th>\n",
       "      <th>problem.3</th>\n",
       "      <th>problem.4</th>\n",
       "      <th>problem.5</th>\n",
       "      <th>problem.6</th>\n",
       "      <th>problem.7</th>\n",
       "      <th>solution/binary classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query paper i</td>\n",
       "      <td>selected citations ij</td>\n",
       "      <td>W2V</td>\n",
       "      <td>D2V</td>\n",
       "      <td>surface similarity</td>\n",
       "      <td>paper sizein Bytes</td>\n",
       "      <td>publication type pair; 1 same type;0 different...</td>\n",
       "      <td>in which percentile (1 to 8) the citation occurs</td>\n",
       "      <td>final decision: 1 is B, 0 is S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q01</td>\n",
       "      <td>C0101</td>\n",
       "      <td>2.098</td>\n",
       "      <td>0.256289676</td>\n",
       "      <td>0.030031591</td>\n",
       "      <td>36240</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q01</td>\n",
       "      <td>C0102</td>\n",
       "      <td>2.117</td>\n",
       "      <td>0.096844971</td>\n",
       "      <td>0.028035853</td>\n",
       "      <td>32202</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q01</td>\n",
       "      <td>C0103</td>\n",
       "      <td>1.973</td>\n",
       "      <td>0.214411901</td>\n",
       "      <td>0.033382998</td>\n",
       "      <td>38899</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q01</td>\n",
       "      <td>C0104</td>\n",
       "      <td>2.235</td>\n",
       "      <td>0.115689246</td>\n",
       "      <td>0.021607683</td>\n",
       "      <td>18009</td>\n",
       "      <td>1</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         problem              problem.1 problem.2    problem.3  \\\n",
       "0  query paper i  selected citations ij       W2V          D2V   \n",
       "1            Q01                  C0101     2.098  0.256289676   \n",
       "2            Q01                  C0102     2.117  0.096844971   \n",
       "3            Q01                  C0103     1.973  0.214411901   \n",
       "4            Q01                  C0104     2.235  0.115689246   \n",
       "\n",
       "            problem.4           problem.5  \\\n",
       "0  surface similarity  paper sizein Bytes   \n",
       "1         0.030031591               36240   \n",
       "2         0.028035853               32202   \n",
       "3         0.033382998               38899   \n",
       "4         0.021607683               18009   \n",
       "\n",
       "                                           problem.6  \\\n",
       "0  publication type pair; 1 same type;0 different...   \n",
       "1                                                  1   \n",
       "2                                                  1   \n",
       "3                                                  0   \n",
       "4                                                  1   \n",
       "\n",
       "                                          problem.7  \\\n",
       "0  in which percentile (1 to 8) the citation occurs   \n",
       "1                                              1000   \n",
       "2                                              1000   \n",
       "3                                              1000   \n",
       "4                                              7000   \n",
       "\n",
       "   solution/binary classification  \n",
       "0  final decision: 1 is B, 0 is S  \n",
       "1                               1  \n",
       "2                               1  \n",
       "3                               0  \n",
       "4                               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../10 whole query articles txt/'\n",
    "# path2 = '../100 cited articles/'\n",
    "\n",
    "# files = []\n",
    "# # r=root, d=directories, f = files\n",
    "# for r, d, f in os.walk(path2):\n",
    "#     print(r)\n",
    "#     print(d)\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"../100 cited articles/C1005.txt\")\n",
    "# tmp = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = pd.unique(data['problem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'query paper i'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Q01\n",
       "2     Q01\n",
       "3     Q01\n",
       "4     Q01\n",
       "5     Q01\n",
       "6     Q01\n",
       "7     Q01\n",
       "8     Q01\n",
       "9     Q01\n",
       "10    Q01\n",
       "Name: problem, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['problem'] == 'Q01']['problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      query paper i\n",
       "1              hello\n",
       "2              hello\n",
       "3              hello\n",
       "4              hello\n",
       "           ...      \n",
       "96               Q10\n",
       "97               Q10\n",
       "98               Q10\n",
       "99               Q10\n",
       "100              Q10\n",
       "Name: problem, Length: 101, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['problem'].replace('Q01', 'hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace query papers with actual contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_problem = pd.unique(data['problem'])\n",
    "for u in uni_problem[1:]:\n",
    "    f = open('../10 whole query articles txt/'+u+'.txt')\n",
    "    tmp = f.read()\n",
    "    data['problem'] = data['problem'].replace(u, tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>problem.1</th>\n",
       "      <th>problem.2</th>\n",
       "      <th>problem.3</th>\n",
       "      <th>problem.4</th>\n",
       "      <th>problem.5</th>\n",
       "      <th>problem.6</th>\n",
       "      <th>problem.7</th>\n",
       "      <th>solution/binary classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query paper i</td>\n",
       "      <td>selected citations ij</td>\n",
       "      <td>W2V</td>\n",
       "      <td>D2V</td>\n",
       "      <td>surface similarity</td>\n",
       "      <td>paper sizein Bytes</td>\n",
       "      <td>publication type pair; 1 same type;0 different...</td>\n",
       "      <td>in which percentile (1 to 8) the citation occurs</td>\n",
       "      <td>final decision: 1 is B, 0 is S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>C0101</td>\n",
       "      <td>2.098</td>\n",
       "      <td>0.256289676</td>\n",
       "      <td>0.030031591</td>\n",
       "      <td>36240</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>C0102</td>\n",
       "      <td>2.117</td>\n",
       "      <td>0.096844971</td>\n",
       "      <td>0.028035853</td>\n",
       "      <td>32202</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>C0103</td>\n",
       "      <td>1.973</td>\n",
       "      <td>0.214411901</td>\n",
       "      <td>0.033382998</td>\n",
       "      <td>38899</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>C0104</td>\n",
       "      <td>2.235</td>\n",
       "      <td>0.115689246</td>\n",
       "      <td>0.021607683</td>\n",
       "      <td>18009</td>\n",
       "      <td>1</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>C1006</td>\n",
       "      <td>2.247</td>\n",
       "      <td>0.276550423</td>\n",
       "      <td>0.028751456</td>\n",
       "      <td>30707</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>C1007</td>\n",
       "      <td>2.218</td>\n",
       "      <td>0.188079829</td>\n",
       "      <td>0.030792555</td>\n",
       "      <td>34563</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>C1008</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.214281735</td>\n",
       "      <td>0.032667587</td>\n",
       "      <td>31950</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>C1009</td>\n",
       "      <td>2.261</td>\n",
       "      <td>0.137207324</td>\n",
       "      <td>0.034078566</td>\n",
       "      <td>54274</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>C1010</td>\n",
       "      <td>2.263</td>\n",
       "      <td>0.256527846</td>\n",
       "      <td>0.033144238</td>\n",
       "      <td>33624</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               problem              problem.1  \\\n",
       "0                                        query paper i  selected citations ij   \n",
       "1     Lexicon-Based Methods for Sentiment Analysis ...                  C0101   \n",
       "2     Lexicon-Based Methods for Sentiment Analysis ...                  C0102   \n",
       "3     Lexicon-Based Methods for Sentiment Analysis ...                  C0103   \n",
       "4     Lexicon-Based Methods for Sentiment Analysis ...                  C0104   \n",
       "..                                                 ...                    ...   \n",
       "96    Learning Subjective Language  Theresa Wilson ...                  C1006   \n",
       "97    Learning Subjective Language  Theresa Wilson ...                  C1007   \n",
       "98    Learning Subjective Language  Theresa Wilson ...                  C1008   \n",
       "99    Learning Subjective Language  Theresa Wilson ...                  C1009   \n",
       "100   Learning Subjective Language  Theresa Wilson ...                  C1010   \n",
       "\n",
       "    problem.2    problem.3           problem.4           problem.5  \\\n",
       "0         W2V          D2V  surface similarity  paper sizein Bytes   \n",
       "1       2.098  0.256289676         0.030031591               36240   \n",
       "2       2.117  0.096844971         0.028035853               32202   \n",
       "3       1.973  0.214411901         0.033382998               38899   \n",
       "4       2.235  0.115689246         0.021607683               18009   \n",
       "..        ...          ...                 ...                 ...   \n",
       "96      2.247  0.276550423         0.028751456               30707   \n",
       "97      2.218  0.188079829         0.030792555               34563   \n",
       "98      2.206  0.214281735         0.032667587               31950   \n",
       "99      2.261  0.137207324         0.034078566               54274   \n",
       "100     2.263  0.256527846         0.033144238               33624   \n",
       "\n",
       "                                             problem.6  \\\n",
       "0    publication type pair; 1 same type;0 different...   \n",
       "1                                                    1   \n",
       "2                                                    1   \n",
       "3                                                    0   \n",
       "4                                                    1   \n",
       "..                                                 ...   \n",
       "96                                                   0   \n",
       "97                                                   1   \n",
       "98                                                   1   \n",
       "99                                                   0   \n",
       "100                                                  1   \n",
       "\n",
       "                                            problem.7  \\\n",
       "0    in which percentile (1 to 8) the citation occurs   \n",
       "1                                                1000   \n",
       "2                                                1000   \n",
       "3                                                1000   \n",
       "4                                                7000   \n",
       "..                                                ...   \n",
       "96                                               2000   \n",
       "97                                               2000   \n",
       "98                                               2000   \n",
       "99                                               1000   \n",
       "100                                              6000   \n",
       "\n",
       "     solution/binary classification  \n",
       "0    final decision: 1 is B, 0 is S  \n",
       "1                                 1  \n",
       "2                                 1  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "..                              ...  \n",
       "96                                1  \n",
       "97                                1  \n",
       "98                                0  \n",
       "99                                1  \n",
       "100                               1  \n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace citations with actual contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_citation = pd.unique(data['problem.1'])\n",
    "for u in uni_citation[1:]:\n",
    "    f = open('../100 cited articles/'+u+'.txt')\n",
    "    tmp = f.read()\n",
    "    data['problem.1'] = data['problem.1'].replace(u, tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>problem.1</th>\n",
       "      <th>problem.2</th>\n",
       "      <th>problem.3</th>\n",
       "      <th>problem.4</th>\n",
       "      <th>problem.5</th>\n",
       "      <th>problem.6</th>\n",
       "      <th>problem.7</th>\n",
       "      <th>solution/binary classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query paper i</td>\n",
       "      <td>selected citations ij</td>\n",
       "      <td>W2V</td>\n",
       "      <td>D2V</td>\n",
       "      <td>surface similarity</td>\n",
       "      <td>paper sizein Bytes</td>\n",
       "      <td>publication type pair; 1 same type;0 different...</td>\n",
       "      <td>in which percentile (1 to 8) the citation occurs</td>\n",
       "      <td>final decision: 1 is B, 0 is S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>Amazon Mechanical Turk for Subjectivity Word ...</td>\n",
       "      <td>2.098</td>\n",
       "      <td>0.256289676</td>\n",
       "      <td>0.030031591</td>\n",
       "      <td>36240</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>Mining WordNet for Fuzzy Sentiment:  Sentimen...</td>\n",
       "      <td>2.117</td>\n",
       "      <td>0.096844971</td>\n",
       "      <td>0.028035853</td>\n",
       "      <td>32202</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>When Specialists and Generalists Work Togethe...</td>\n",
       "      <td>1.973</td>\n",
       "      <td>0.214411901</td>\n",
       "      <td>0.033382998</td>\n",
       "      <td>38899</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>Distilling Opinion in Discourse: A Preliminar...</td>\n",
       "      <td>2.235</td>\n",
       "      <td>0.115689246</td>\n",
       "      <td>0.021607683</td>\n",
       "      <td>18009</td>\n",
       "      <td>1</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Similarity-Based Estimation of Word Cooccurre...</td>\n",
       "      <td>2.247</td>\n",
       "      <td>0.276550423</td>\n",
       "      <td>0.028751456</td>\n",
       "      <td>30707</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Recognizing Expressions of Commonsense Psycho...</td>\n",
       "      <td>2.218</td>\n",
       "      <td>0.188079829</td>\n",
       "      <td>0.030792555</td>\n",
       "      <td>34563</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Automatic Detection of Text Genre  Xerox Palo...</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.214281735</td>\n",
       "      <td>0.032667587</td>\n",
       "      <td>31950</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Building a Large Annotated Corpus of English:...</td>\n",
       "      <td>2.261</td>\n",
       "      <td>0.137207324</td>\n",
       "      <td>0.034078566</td>\n",
       "      <td>54274</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Proceedings of the 40th Annual Meeting of the...</td>\n",
       "      <td>2.263</td>\n",
       "      <td>0.256527846</td>\n",
       "      <td>0.033144238</td>\n",
       "      <td>33624</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               problem  \\\n",
       "0                                        query paper i   \n",
       "1     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "2     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "3     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "4     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "..                                                 ...   \n",
       "96    Learning Subjective Language  Theresa Wilson ...   \n",
       "97    Learning Subjective Language  Theresa Wilson ...   \n",
       "98    Learning Subjective Language  Theresa Wilson ...   \n",
       "99    Learning Subjective Language  Theresa Wilson ...   \n",
       "100   Learning Subjective Language  Theresa Wilson ...   \n",
       "\n",
       "                                             problem.1 problem.2    problem.3  \\\n",
       "0                                selected citations ij       W2V          D2V   \n",
       "1     Amazon Mechanical Turk for Subjectivity Word ...     2.098  0.256289676   \n",
       "2     Mining WordNet for Fuzzy Sentiment:  Sentimen...     2.117  0.096844971   \n",
       "3     When Specialists and Generalists Work Togethe...     1.973  0.214411901   \n",
       "4     Distilling Opinion in Discourse: A Preliminar...     2.235  0.115689246   \n",
       "..                                                 ...       ...          ...   \n",
       "96    Similarity-Based Estimation of Word Cooccurre...     2.247  0.276550423   \n",
       "97    Recognizing Expressions of Commonsense Psycho...     2.218  0.188079829   \n",
       "98    Automatic Detection of Text Genre  Xerox Palo...     2.206  0.214281735   \n",
       "99    Building a Large Annotated Corpus of English:...     2.261  0.137207324   \n",
       "100   Proceedings of the 40th Annual Meeting of the...     2.263  0.256527846   \n",
       "\n",
       "              problem.4           problem.5  \\\n",
       "0    surface similarity  paper sizein Bytes   \n",
       "1           0.030031591               36240   \n",
       "2           0.028035853               32202   \n",
       "3           0.033382998               38899   \n",
       "4           0.021607683               18009   \n",
       "..                  ...                 ...   \n",
       "96          0.028751456               30707   \n",
       "97          0.030792555               34563   \n",
       "98          0.032667587               31950   \n",
       "99          0.034078566               54274   \n",
       "100         0.033144238               33624   \n",
       "\n",
       "                                             problem.6  \\\n",
       "0    publication type pair; 1 same type;0 different...   \n",
       "1                                                    1   \n",
       "2                                                    1   \n",
       "3                                                    0   \n",
       "4                                                    1   \n",
       "..                                                 ...   \n",
       "96                                                   0   \n",
       "97                                                   1   \n",
       "98                                                   1   \n",
       "99                                                   0   \n",
       "100                                                  1   \n",
       "\n",
       "                                            problem.7  \\\n",
       "0    in which percentile (1 to 8) the citation occurs   \n",
       "1                                                1000   \n",
       "2                                                1000   \n",
       "3                                                1000   \n",
       "4                                                7000   \n",
       "..                                                ...   \n",
       "96                                               2000   \n",
       "97                                               2000   \n",
       "98                                               2000   \n",
       "99                                               1000   \n",
       "100                                              6000   \n",
       "\n",
       "     solution/binary classification  \n",
       "0    final decision: 1 is B, 0 is S  \n",
       "1                                 1  \n",
       "2                                 1  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "..                              ...  \n",
       "96                                1  \n",
       "97                                1  \n",
       "98                                0  \n",
       "99                                1  \n",
       "100                               1  \n",
       "\n",
       "[101 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = data[['problem', 'problem.1', 'solution/binary classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>problem.1</th>\n",
       "      <th>solution/binary classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query paper i</td>\n",
       "      <td>selected citations ij</td>\n",
       "      <td>final decision: 1 is B, 0 is S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>Amazon Mechanical Turk for Subjectivity Word ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>Mining WordNet for Fuzzy Sentiment:  Sentimen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>When Specialists and Generalists Work Togethe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lexicon-Based Methods for Sentiment Analysis ...</td>\n",
       "      <td>Distilling Opinion in Discourse: A Preliminar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Similarity-Based Estimation of Word Cooccurre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Recognizing Expressions of Commonsense Psycho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Automatic Detection of Text Genre  Xerox Palo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Building a Large Annotated Corpus of English:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Learning Subjective Language  Theresa Wilson ...</td>\n",
       "      <td>Proceedings of the 40th Annual Meeting of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               problem  \\\n",
       "0                                        query paper i   \n",
       "1     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "2     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "3     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "4     Lexicon-Based Methods for Sentiment Analysis ...   \n",
       "..                                                 ...   \n",
       "96    Learning Subjective Language  Theresa Wilson ...   \n",
       "97    Learning Subjective Language  Theresa Wilson ...   \n",
       "98    Learning Subjective Language  Theresa Wilson ...   \n",
       "99    Learning Subjective Language  Theresa Wilson ...   \n",
       "100   Learning Subjective Language  Theresa Wilson ...   \n",
       "\n",
       "                                             problem.1  \\\n",
       "0                                selected citations ij   \n",
       "1     Amazon Mechanical Turk for Subjectivity Word ...   \n",
       "2     Mining WordNet for Fuzzy Sentiment:  Sentimen...   \n",
       "3     When Specialists and Generalists Work Togethe...   \n",
       "4     Distilling Opinion in Discourse: A Preliminar...   \n",
       "..                                                 ...   \n",
       "96    Similarity-Based Estimation of Word Cooccurre...   \n",
       "97    Recognizing Expressions of Commonsense Psycho...   \n",
       "98    Automatic Detection of Text Genre  Xerox Palo...   \n",
       "99    Building a Large Annotated Corpus of English:...   \n",
       "100   Proceedings of the 40th Annual Meeting of the...   \n",
       "\n",
       "     solution/binary classification  \n",
       "0    final decision: 1 is B, 0 is S  \n",
       "1                                 1  \n",
       "2                                 1  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "..                              ...  \n",
       "96                                1  \n",
       "97                                1  \n",
       "98                                0  \n",
       "99                                1  \n",
       "100                               1  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b.to_csv('data_bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
